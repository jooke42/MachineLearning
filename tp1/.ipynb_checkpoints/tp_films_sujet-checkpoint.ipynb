{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    " # Messages associés dans des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Ce TP a pour but de mettre en œuvre la paramétrisation de messages par la technique des \"sacs de mots\" et de regrouper ces messages par l’algorithme des K-moyennes. \n",
    "Dans un premier temps vous travaillerez sur des messages  \"jouets\" que vous aurez choisis pour vous familiariser avec les différentes étapes de la paramétrisation (CountVectorizer puis Stemming et TF-IDF) et  étudier l’évolution de l’algorithme KMeans.\n",
    "\n",
    "Dans un second temps, vous analyserez les synopsis de 100 films récupérées sur wikipedia et IMDb, afin d'identifier **automatiquement** les thèmes récurrents dans ces films.\n",
    "\n",
    "Les modules python à utiliser pour ce TP sont numpy, nltk.stem, sklearn.feature_extraction.text, sklearn.cluster et sklearn.datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Messages \"jouets\" - Prise en main des outils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Choisir un corpus (une liste de chaines de caractères) d’une dizaine de messages courts (quelques mots) en français, relatifs à **deux** «thèmes» de votre choix bien distincts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "corpus=['vous êtes excellents', 'les étudiants sont souvent excellents', \n",
    "        'les étudiants aiment bien rigoler', 'rigoler est excellent pour la santé',\n",
    "        'étudier est excellent', 'que la montagne est belle en hiver',\n",
    "        'en hiver il fait beau mais froid','la neige en montagne est belle',\n",
    "        'la neige en hiver est pénible', 'le froid en hiver est pénible']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Transformation de documents textuels en vecteurs numériques\n",
    "\n",
    "Afin d'appliquer les méthodes d'apprentissage automatique, il est nécessaire de convertir les documents textuels en vecteurs numériques. \n",
    "\n",
    "On peut faire cela à l'aide de la méthode *fit_transform()* de  la classe *CountVectorizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "L'une des operations effectuées par cette méthode est de construire le **dictionnaire des mots** qui apparaissent dans la totalité du corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille du corpus :  10\n",
      "taille du vocabulaire :  29\n",
      "\n",
      "{'vous': 25, 'êtes': 28, 'excellents': 7, 'les': 14, 'étudiants': 26, 'sont': 23, 'souvent': 24, 'aiment': 0, 'bien': 3, 'rigoler': 21, 'est': 5, 'excellent': 6, 'pour': 18, 'la': 12, 'santé': 22, 'étudier': 27, 'que': 20, 'montagne': 16, 'belle': 2, 'en': 4, 'hiver': 10, 'il': 11, 'fait': 8, 'beau': 1, 'mais': 15, 'froid': 9, 'neige': 17, 'pénible': 19, 'le': 13}\n"
     ]
    }
   ],
   "source": [
    "M,N=X.shape\n",
    "\n",
    "print(\"taille du corpus : \",M)\n",
    "print(\"taille du vocabulaire : \",N)\n",
    "print()\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Le résultat de la méthode *fit_transform()* est la **matrice des occurrences** des mots, que l'on peut  visualiser par la méthode *toarray()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Dans la matrice des occurrences, une ligne corresponde à un document particulier, tandis qu'une colonne corresponde à l'un des mots dans le dictionnaire. \n",
    "\n",
    "Par exemple, la première ligne de la matrice est la représentation numérique du premier document du corpus. Remarquez la correspondance directe entre la position des composants non-nuls dans le vecteur et la position des mots dans le dictionnaire !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document du corpus:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ee2d84f10081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Document du corpus:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<< \"\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" >>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"Représentation numerique:\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(\"Document du corpus:\")\n",
    "print(\"<< \" +  corpus[0] + \" >>\")\n",
    "print()\n",
    "print( \"Représentation numerique:\" )\n",
    "print( X[0].toarray() )\n",
    "print()\n",
    "print( \"Correspondance entre le vecteur et le dictionnaire:\" )\n",
    "print( (X[0] != 0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "-----\n",
    "\n",
    "**Un document est donc représenté par un vecteur de la même taille que le dictionnaire, dont la composante i indique le nombre d'occurrences du i-ème mot du dictionnaire dans le document.**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Une fois transformé les documents en vecteurs numériques, ils peuvent être traités comme des points dans un espace euclidien tel que $\\mathbb{R}^N$. \n",
    "\n",
    "Cela vous permet de calculer la matrice des distances (2 à 2) entre les documents de votre corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-de481a004c0c>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-de481a004c0c>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    dist_corpus = <<ADD CODE HERE>>\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': '{: 0.2f}'.format}) # definit la visualisation des nombres réels\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# calcule les distances entre les documents\n",
    "dist_corpus = <<ADD CODE HERE>>\n",
    "\n",
    "\n",
    "print(\"Matrice des distances:\")\n",
    "print(dist_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "La position $(i,j)$ de cette matrice contient la distance euclidienne entre les documents $i$ et $j$ de votre corpus. \n",
    "\n",
    "Vous pouvez explorer les similarités dans vos données au travers du *positionnement multidimensionnel (MDS)*, une technique statistique qui perment de visualiser l'information à l'aide d'un graphe 2D ou 3D. Voici les codes python pour visualiser les documents comme des points 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b8d5a385bd5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# transforme les documents en points 2D.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMDS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdissimilarity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"precomputed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdist_corpus\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# visualise les points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dist_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# transforme les documents en points 2D.\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "pos = mds.fit_transform( dist_corpus )\n",
    "\n",
    "# visualise les points\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "plt.scatter( pos[:,0], pos[:,1],  c='white', marker='o', s=200)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "# ajoute le début du document à coté de chaque point\n",
    "for i in range(len(pos)):\n",
    "    ax.text(pos[i,0]-0.2, pos[i,1]+0.1, corpus[i], size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Dans la figure ci-dessus, un point représente l'un des documents que vous avez rédigé. \n",
    "\n",
    "Vous pouvez utiliser des couleurs differentes pour distinguer les deux thèmes sur lesquels portent les documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-870813236b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListedColormap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pos' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "# indiquez une label pour chaque document (0=premier thème, 1=deuxieme thème)\n",
    "labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]  # TODO : replir ce vecteur en accord avec vos documents\n",
    "\n",
    "# visualise les points\n",
    "colors = ['red', 'blue']\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "plt.scatter( pos[:,0], pos[:,1], s=200, c=labels, cmap=matplotlib.colors.ListedColormap(colors) )\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "# ajoute le début du document à coté de chaque point\n",
    "for i in range(len(pos)):\n",
    "    ax.text(pos[i,0]-0.2, pos[i,1]+0.1, corpus[i], size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "**Ces points sont-ils regroupés en accord avec vos deux thèmes ?** \n",
    "\n",
    "Si les documents que vous avez rédigé portent sur deux thèmes bien identifiés et distincts, la réponse est affirmative ! \n",
    "\n",
    "L'idée est que les documents contenant des mots semblables sont *proches*, ce qui refléte des contenus de significations similaires. \n",
    "\n",
    "*(Eventuellement, modifier votre corpus pour que ce soit le cas.)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Classer les documents en deux groupes\n",
    "\n",
    "La question que nous posons est la suivante :\n",
    "\n",
    "**Sur la base de l'observation précédente, peut-on regrouper *automatiquement* les documents ayant des contenus de signification similaire ?**\n",
    "\n",
    "La réponse est affirmative. Pour ce faire, vous pouvez utiliser la méthode *fit_predict()* de la classe *KMeans*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-e680d1361a71>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-e680d1361a71>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    Ckm = clust.<<ADD CODE HERE>>\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# définit les options de classification\n",
    "#  - n_clusters=2 --> deux clusters\n",
    "#  - verbose=1    --> affiche l'évolution du critère pour chaque initialisation\n",
    "clust = KMeans(n_clusters=2, n_init=10, init='k-means++', verbose=1)\n",
    "\n",
    "# calcule les labels de chaque document du corpus\n",
    "Ckm = clust.<<ADD CODE HERE>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Le résultat de cette méthode est un vecteur de labels, où **le label i indique la classe du document i**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe des documents:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Ckm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e2f60e625189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classe des documents:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCkm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Ckm' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Classe des documents:\")\n",
    "print(Ckm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Vous pouvez visualiser la classification obtenue sur un graphe 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2b4fa7093177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCkm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListedColormap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pos' is not defined"
     ]
    }
   ],
   "source": [
    "colors = ['red', 'blue']\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "\n",
    "plt.scatter( pos[:,0], pos[:,1], s=200, c=Ckm, cmap=matplotlib.colors.ListedColormap(colors) )\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(len(pos)):\n",
    "    ax.text(pos[i,0]-0.2, pos[i,1]+0.1, corpus[i], size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "** Les documents sont-ils classifiés en accord avec vos deux thèmes ? **\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Pour interpréter les résultats, vous pouvez analyser les *centroides* calculés par l'algorithme K-Means. \n",
    "\n",
    "Plus précisément, vous pouvez afficher les *mots clés* associés à chaque centroide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6c66d982a618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmots0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmots1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Thème 0:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmots0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "mots0 = vectorizer.inverse_transform( clust.cluster_centers_[0] )\n",
    "mots1 = vectorizer.inverse_transform( clust.cluster_centers_[1] )\n",
    "\n",
    "print(\"Thème 0:\")\n",
    "print( ' '.join(mots0[0]) )\n",
    "print()\n",
    "print(\"Thème 1:\")\n",
    "print( ' '.join(mots1[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Remarquez la présence de *mots inutiles* (est, il, la, ...) et de *mots similaires* (excellent , excellents, ...) parmi les mots clés de chaque thème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Réduction de la taille du vocabulaire\n",
    "\n",
    "Il est raisonnable de ne pas prendre en compte les *stop words*, à savior les mots tels que les articles, les verbes auxilliaires, les conjonctions, les liaisons, et tous les mots très usuels qui n'apportent aucune information sur le sens du document. De plus, pour réduire ultérieurement les redondances, on ne peut que garder la racine des mots au travers d'une opération de *stemming*. \n",
    "\n",
    "**Refaites la conversion des documents textuels en vecteurs numériques, cette fois avec le stemming et sans les stop words.**\n",
    "\n",
    "En premier lieu, redéfinissez la classes *FrenchStemmedCountVectorizer* comme montré dans le cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-8947815fb55e>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-8947815fb55e>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    <<ADD CODE HERE>>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# définit les \"stop words\" français\n",
    "import nltk\n",
    "import nltk.stem\n",
    "from nltk.corpus import stopwords\n",
    "stwf=stopwords.words('french')\n",
    "\n",
    "# définit le stemmer en français\n",
    "french_stemmer=nltk.stem.SnowballStemmer('french')\n",
    "class FrenchStemmedCountVectorizer(CountVectorizer): # hérite de CountVectorizer\n",
    "    def build_analyzer(self):\n",
    "        \n",
    "        <<ADD CODE HERE>>\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Ensuite, appelez la méthode *fit_transform()* sur votre corpus de documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-d8943fa095f3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-d8943fa095f3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    X = Fvectorizer.<<ADD CODE HERE>>\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Fvectorizer = FrenchStemmedCountVectorizer(min_df=1, stop_words=stwf)\n",
    "X = Fvectorizer.<<ADD CODE HERE>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Afficher le nouveau dictionnaire des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8e13d61c6987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"taille du corpus : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"taille du vocabulaire : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "M,N=X.shape\n",
    "\n",
    "print(\"taille du corpus : \",M)\n",
    "print(\"taille du vocabulaire : \",N)\n",
    "print()\n",
    "print(Fvectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "On peut visualizer les documents transformés en utilisant les mots du nouveau dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Fvectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8591e84b94c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# recupere les mots du dictionnaire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# visualise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Fvectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# recupere les mots du dictionnaire \n",
    "new_corpus = Fvectorizer.inverse_transform( X )\n",
    "\n",
    "# visualise\n",
    "padding = len( max(corpus, key=len) )\n",
    "for i in range(M):\n",
    "    print( \"%s ==> %s\" % (corpus[i].ljust(padding), ' '.join(new_corpus[i])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Recalculez la matrices des distances et visualisez-la comme montré précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'euclidean_distances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4314a1c647e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# distance des documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdist_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# transforme les documents en points 2D.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMDS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdissimilarity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"precomputed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'euclidean_distances' is not defined"
     ]
    }
   ],
   "source": [
    "# distance des documents\n",
    "dist_corpus = euclidean_distances(X)\n",
    "\n",
    "# transforme les documents en points 2D.\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "pos = mds.fit_transform( dist_corpus )\n",
    "\n",
    "# visualise les points\n",
    "colors = ['red', 'blue']\n",
    "fig, ax = plt.subplots(figsize=(17, 9))\n",
    "plt.scatter( pos[:,0], pos[:,1], s=200, c=labels, cmap=matplotlib.colors.ListedColormap(colors) )\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "# ajoute le début du document à coté de chaque point\n",
    "for i in range(len(pos)):\n",
    "    ax.text(pos[i,0]-0.2, pos[i,1]+0.1, corpus[i], size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Reclassifiez les documents à l'aide de l'algorithme K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-bf3423c1c6b2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-bf3423c1c6b2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    clust = KMeans(<<ADD CODE HERE>>)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# définit les options de classification\n",
    "clust = KMeans(<<ADD CODE HERE>>)\n",
    "\n",
    "# calcule les labels de chaque document du corpus\n",
    "Ckm = clust.<<ADD CODE HERE>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Pour interpréter les résultats, vous pouvez reanalyser les centroides calculés par l'algorithme K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Fvectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-711c06df0fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmots0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmots1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Thème 0:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmots0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Fvectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "mots0 = Fvectorizer.inverse_transform( clust.cluster_centers_[0] )\n",
    "mots1 = Fvectorizer.inverse_transform( clust.cluster_centers_[1] )\n",
    "\n",
    "print(\"Thème 0:\")\n",
    "print( ' '.join(mots0[0]) )\n",
    "print()\n",
    "print(\"Thème 1:\")\n",
    "print( ' '.join(mots1[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "**Maintenant, vous devriez avoir une indication plus précise des mots clés associés aux deux thèmes.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Top 100 Greatest Movies of All Time\n",
    "\n",
    "Pour montrer l'intérêt de la classification de messages, nous analyseront les synopsis de 100 films (récupérées sur wikipedia et IMDb), afin d'identifier **automatiquement** les thèmes récurrents dans ces films.\n",
    "\n",
    "Vous trouverez les données textuelles dans les fichiers qui accompagnent le présent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Si beautifulsoup pas installé\n",
    "# !pip3 install BeautifulSoup4 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# récupère 100 films\n",
    "titles = open('title_list.txt').read().split('\\n')\n",
    "titles = titles[:100]\n",
    "\n",
    "# récupère les liens sur IMDb\n",
    "links = open('link_list_imdb.txt').read().split('\\n')\n",
    "links = links[:100]\n",
    "\n",
    "# récupère les genres\n",
    "genres = open('genres_list.txt').read().split('\\n')\n",
    "genres = genres[:100]\n",
    "\n",
    "# récupère les synopses de wikipedia\n",
    "synopses_wiki = open('synopses_list_wiki.txt', encoding=\"utf8\").read().split('\\n BREAKS HERE')\n",
    "synopses_wiki = synopses_wiki[:100]\n",
    "\n",
    "# récupère les synopses de IMDb\n",
    "synopses_imdb = open('synopses_list_imdb.txt').read().split('\\n BREAKS HERE')\n",
    "synopses_imdb = synopses_imdb[:100]\n",
    "\n",
    "# nettoie les synopses de wikipedia\n",
    "synopses_clean_wiki = []\n",
    "for text in synopses_wiki:\n",
    "    text = BeautifulSoup(text, 'html.parser').getText()\n",
    "    synopses_clean_wiki.append(text)\n",
    "synopses_wiki = synopses_clean_wiki\n",
    "\n",
    "# nettoie les synopses de IMDb\n",
    "synopses_clean_imdb = []\n",
    "for text in synopses_imdb:\n",
    "    text = BeautifulSoup(text, 'html.parser').getText()\n",
    "    synopses_clean_imdb.append(text)\n",
    "synopses_imdb = synopses_clean_imdb\n",
    "\n",
    "# fusionne les deux synopses\n",
    "synopses = []\n",
    "for i in range(len(synopses_wiki)):\n",
    "    item = synopses_wiki[i] + synopses_imdb[i]\n",
    "    synopses.append(item)\n",
    "    \n",
    "# génère les indices pour chaque élément dans le corpus\n",
    "ranks = []\n",
    "for i in range(0,len(titles)):\n",
    "    ranks.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Voici les données relatives à quelque film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Godfather\n",
      "\n",
      "http://www.imdb.com/title/tt0068646/\n",
      "\n",
      "[u' Crime', u' Drama']\n",
      "\n",
      "Plot  [edit]  [  [  edit  edit  ]  ]  \n",
      "  On the day of his only daughter's wedding, Vito Corleone hears requests in his role as the Godfather, the Don of a New York crime family. Vito's youngest son, Michael, in a Marine Corps uniform, introduces his girlfriend, Kay Adams, to his family at the sprawling reception. Vito's godson Johnny Fontane, a popular singer, pleads for help in securing a coveted movie role, so Vito dispatches his consigliere, Tom Hagen, to Los Angeles to influence the abrasi\n"
     ]
    }
   ],
   "source": [
    "idx = 0; # changer l'indice pour afficher un film different\n",
    "\n",
    "print( titles[idx] )\n",
    "print()\n",
    "print( links[idx] )\n",
    "print()\n",
    "print( genres[idx] )\n",
    "print()\n",
    "print( synopses[idx][1:500] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Etape 1 : Transformation TF-IDF\n",
    "\n",
    "La première étape consiste à convertir les documents textuels en vecteur numériques. Pour ce faire, vous utiliserez la transformation TF-IDF vue en cours.\n",
    "\n",
    "La classe *TfidfVectorizer* permet obtenir des vecteurs de composantes tf-idf. Il est cependant nécessaire, si l'on veut reduire le dictionnaire avant de construire les vecteurs tf-idf, de créer une nouvelle classe *StemmedTfidfVectorizer*, comme vous l'avez fait précédemment pour *StemmedCountVectorizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-83278e2cf333>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-83278e2cf333>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <<ADD CODE HERE>>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<<ADD CODE HERE>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Appelez la méthode *fit_transform()* sur les synopsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-83278e2cf333>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-83278e2cf333>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <<ADD CODE HERE>>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<<ADD CODE HERE>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Afficher les informations sur le dictionnaire des mots. Remarquez la taille de celui-ci sur une application réelle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-83278e2cf333>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-83278e2cf333>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <<ADD CODE HERE>>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<<ADD CODE HERE>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Calculez la matrice des distances et afficher le résultat dans un graphe 2D (comme montré dans l'exemple precedent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-83278e2cf333>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-83278e2cf333>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <<ADD CODE HERE>>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<<ADD CODE HERE>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "L'indice de chaque point vous permet de recuperer le titre correspondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre du film n° 9 : Titanic\n"
     ]
    }
   ],
   "source": [
    "idx = 9 \n",
    "\n",
    "print(\"Titre du film n°\", idx, \": \" + titles[9] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "**Vous pouvez modifier les paramètres *min_df* et *max_df* dans la fonction *StemmedTfidfVectorizer()*, afin de changer la taille du dictionnaire. L'impact de ce changement sera visible sur la figure ci-dessus.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Etape 2 : Clustering\n",
    "\n",
    "La deuxieme étape consiste à regrouper les films en utilisant l'algorithme *K-Means* vu en cours.\n",
    "\n",
    "Vous avez le choix sur un paramètre : le **nombre de thèmes** dont les films seront regroupés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-83278e2cf333>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-83278e2cf333>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <<ADD CODE HERE>>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<<ADD CODE HERE>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Vous pouvez visualiser la classification obtenue sur un graphe 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9b529c8a412a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCkm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListedColormap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pos' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "colors = ['pink', 'lightblue', 'lightgreen', 'orange', 'yellow', 'red', 'green', 'blue', 'cyan', 'brown']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 15))\n",
    "plt.scatter( pos[:,0], pos[:,1], s=300, c=Ckm, cmap=matplotlib.colors.ListedColormap(colors) )\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(len(pos)):\n",
    "    ax.text(pos[i,0]+0.01, pos[i,1]+0.01, ranks[i], size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Vouz pouvez analyser les résultats de plusieurs points de vue. \n",
    "\n",
    "- Afficher l'histogrammme des labels obtenus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-83278e2cf333>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-83278e2cf333>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <<ADD CODE HERE>>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<<ADD CODE HERE>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    " - Visualizer les mots clés de chaque thème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-83278e2cf333>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-83278e2cf333>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <<ADD CODE HERE>>\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<<ADD CODE HERE>>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "latex_bib.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "ctrl-e"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "fr",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#39ff00"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "171px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "4",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
