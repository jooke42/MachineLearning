{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD 3 - Représentation d'images et validation croisée\n",
    "Dans ce TD, nous nous interesons à:\n",
    "- la représentation d'images par leur [histogramme couleur](https://en.wikipedia.org/wiki/Color_histogram);\n",
    "- la validation croisée de hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En indexation de donnée par le contenu, une problématique courante est la recherche par similarité de documents. Le but de trier l'ensemble des documents d'une base de donnée du plus similaire au moins similaire par rapport à un document requête en utilisant uniquement des informations extraites des documents.\n",
    "\n",
    "Dans ce TD, nous voulons faire de la recherche par similarité d'images. Comme pour le texte, nous ne pouvons pas utiliser directement l'image. Nous devons dans un premier temps extraire des paramètres (features) des images. Puis nous utilisons une métrique pour mesurer la similarité entre les images. Nous pouvons alors trier les images par rapport à leur similarité avec l'image requête.\n",
    "\n",
    "## Holidays dataset\n",
    "Pour nos expériences, nous utilisons la base d'image [Holidays dataset](http://lear.inrialpes.fr/~jegou/data.php). Cette base de 1491 images provenant de photos de vacances. Les autres ont pris en compte de tester la robustesse de diverses attaques: les rotations, les changements de points de vue et d'éclairage, le flou, etc. L'ensemble de données comprend une très grande variété de types de scène (effets naturels, artificiels, d'eau et de feu, etc.). L'ensemble de données  sont regroupé en 500 groupes d'images, chacun représentant une scène ou un objet distinct. La première image de chaque groupe est l'image de requête et l'objectif est de récupérer en premier les autres images du groupe.\n",
    "\n",
    "<center><img src=\"./Holidays.jpg\" width=600px></center>\n",
    "\n",
    "Le code suivant permet de crée la liste des images de la base :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "images_dir = './Holidays_dataset'\n",
    "\n",
    "image_file_names = sorted([os.path.split(f)[1] for f in glob.glob(os.path.join(images_dir, '*.jpg'))])\n",
    "\n",
    "N = len(image_file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le groupe des images et leurs indices dans le groupe sont codés dans leurs noms. Par exemple l'image `100502.jpg` est la $3^\\text{éme}$ image du $6^\\text{éme}$ groupe :\n",
    "- `1`**`005`**`02.jpg` $\\Rightarrow 6^\\text{éme}$ groupe\n",
    "- `1005`**`02`**`.jpg` $\\Rightarrow 3^\\text{éme}$ image du groupe\n",
    "L'image qui est utilisé comme requête dans chaque groupe est la $1^\\text{ére}$ image du groupe (`1005`**`00`**`.jpg`).\n",
    "\n",
    "Le code suivant permet de récupéré les groupes de chaque image et les images requêtes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.asarray([int(f[1:4]) for f in image_file_names]) # verite terrain: recupere pour chaque imag le num de son groupe (ex:005 au dessus) \n",
    "queries = np.asarray([f.endswith('00.jpg') for f in image_file_names]) # vecteur de booléens : VRAI aux indices des images servant de requetes (celles finissant par 000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `y` $\\in \\mathbb{N}^N$ est le vecteur de l'indice de groupe pour chaque image.\n",
    "- `queries` $\\in \\{\\text{False},\\text{True}\\}^N$ est le vecteur booléen qui indique si l'image est une requête ou non.\n",
    "\n",
    "**À faire -** Écrivez le code pour ouvrir toutes les images de la base et stockées les dans la liste `images`.\n",
    "\n",
    "**Aide -** Regardez l'aide des fonctions : [`scipy.misc.imread`](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.misc.imread.html), [`os.path.join`](https://docs.python.org/3/library/os.path.html#os.path.join) et [les listes en python](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "\n",
    "images = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À faire** - À l'aide de la fonction [`matplotlib.pyplot.imshow`](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.imshow), visualisez un image de la base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À faire** - Affichez les dimentions de l'image ([`numpy.ndarray.shape`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** - À quoi corresponde ces trois dimensions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la première dimension est ????\n",
    "- la deuxième dimension est ????\n",
    "- la troisième dimension est ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramme couleur\n",
    "\n",
    "Pour représenté les images, nous utilisons l'histogramme de la proportion des couleurs dans l'image. \n",
    "\n",
    "Le codage [RGB](https://en.wikipedia.org/wiki/RGB_color_model) (Red, Green, Blue) sur 24 bits (3 canaux de 8 bits) permet de coder : 16777216 couleurs differentes.\n",
    "\n",
    "**Question -** Est il judicieux d'utiliser toutes les couleurs pour calculer l'histogramme couleur des images ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduction du nombre de couleur\n",
    "Nous voulons alors réduire le nombre de couleur utilisé. Pour cela, il est judicieux de rechercher les $P$ couleurs les plus couramment utilisées dans nos images et ensuite de remplacer pour chaque pixel de chaque image la couleur du pixel par la couleur la plus proche parmi les $P$ couleurs les plus courantes. Cette méthode s'appelle la [quantification couleur](https://en.wikipedia.org/wiki/Color_quantization) et elle est basé sur l'utilisation d'algorithme de [clustering](https://en.wikipedia.org/wiki/Cluster_analysis).\n",
    "\n",
    "Pour trouver les couleurs les plus couramment utilisées, nous devons extraire des images l'ensemble des pixels de toute les images et les rassembler dans une matrice.\n",
    "\n",
    "**À faire -** Ecrivez le code pour extraire tous les pixels de toutes les images stockées dans la matrice `rgb_samples` de dimension $\\text{nombre total de pixel}\\times 3$\n",
    "\n",
    "**Aide -** Regardez l'aide des fonctions : [`numpy.reshape`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) (lire attentivement la description du paramètre `newshape`) et [`numpy.vstack`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgb_samples = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons un échantillon de plus de 72 millions de couleurs RGB, c'est beaucoup trop. Nous allons en choisir aléatoirement un petit nombre.\n",
    "\n",
    "**À faire -** Ecrivez le code pour choisir aléatoirement 100000 exemples de couleurs RGB dans la matrice `rgb_samples` et stockez les à nouveau dans la matrice `rgb_samples`.\n",
    "\n",
    "**Aide -** Regardez l'aide de la fonction : [`numpy.random.choice`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html) (lire attentivement la description du paramètre `replace`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour déterminer les $P$ couleur les plus courantes, nous allons utiliser l'algorithme [K-Means](https://en.wikipedia.org/wiki/K-means_clustering).\n",
    "\n",
    "**À faire -** Ecrivez le code pour effectuer un clustering de 64 clusters ($P=128$) avec algorithme K-Means sur notre échantillon de couleur RGB `rgb_samples`.\n",
    "\n",
    "**Aide -** Regardez l'aide de la fonction : [`sklearn.cluster.KMeans`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "\n",
    "**Conseil -** Fixez le paramète `n_init` à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "P = 128\n",
    "\n",
    "kms = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivant permet de réorganiser les couleurs  obtenue par le clustering dans l'ordre des teintes du codage couleur [HSV](https://fr.wikipedia.org/wiki/Teinte_Saturation_Valeur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import colorsys\n",
    "def reorganize_clusters(kms):\n",
    "    h = np.zeros((kms.n_clusters, ))\n",
    "    for i in range(kms.n_clusters):\n",
    "        r,g,b = kms.cluster_centers_[i,:]/255.0\n",
    "        h[i] = colorsys.rgb_to_hsv(r, g, b)[0]\n",
    "    idx = np.argsort(h)\n",
    "    kms.cluster_centers_ = kms.cluster_centers_[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous l'appliquons sur notre objet KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reorganize_clusters(kms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À faire -** Ecrivez le code pour afficher l'image de la palette couleur obtenu avec le clustering (par exemple, une image de 8 ligne par ? pixels).\n",
    "\n",
    "**Aide -** Regardez l'aide des fonctions : [`numpy.reshape`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) et [`matplotlib.pyplot.imshow`](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.imshow)\n",
    "\n",
    "**Conseil -** Ajoutez le paramètre : `interpolation='nearest'` pour la fonction `imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "palette = kms.cluster_centers_.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons voir l'effet de la quantification couleur sur une image.\n",
    "\n",
    "**À faire -** Choisissez aléatoirement une des images et écrivez le code pour obtenir sa version quantifiée. Puis affichez les deux images pour les comparer.\n",
    "\n",
    "**Aide -** Regardez l'aide des fonctions : [`sklearn.cluster.KMeans.predict`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.predict), [`numpy.reshape`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) et [`matplotlib.pyplot.imshow`](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.imshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I = ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous maintenant calculer, histogramme couleur d'un image avec les couleurs obtenu apres quantification.\n",
    "\n",
    "**À faire -** Completez la fonction `def compute_hist(kmeans, I)` qui retourne un vecteur contenant la proportion de chaque couleur dans dans l'image `I`.\n",
    "\n",
    "**Aide -** Regardez l'aide des fonctions : [`sklearn.cluster.KMeans.predict`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.predict), [`numpy.reshape`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) et [`numpy.unique`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html) (lire attentivement la description du paramètre `return_counts`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_hist(kmeans, I):\n",
    "    x = np.zeros((kmeans.n_clusters, ))\n",
    "    idx = kmeans.predict(I.astype(np.float64).reshape((-1,3)))\n",
    "    idv, v = np.unique(idx, return_counts=True)\n",
    "    x[idv] = v\n",
    "    return x/np.sum(x).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons visualier l'histogramme couleur une image\n",
    "\n",
    "**À faire -** Choisissez aléatoirement une des images, utilisez la fonction `def compute_hist(kmeans, I)` pour calculer son histogramme couleur et affichez le.\n",
    "\n",
    "**Aide -** Regardez l'aide de la fonction : [`matplotlib.pyplot.bar`](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.bar)\n",
    "\n",
    "\n",
    "**Conseil -** Ajoutez les paramètres : `width = 1`, `color=palette/255.0` et `edgecolor = 'none'` pour la fonction `bar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I = ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À faire -** Ecrivez le code pour calculer l'histogramme couleur de toutes les images et stockez les dans la matrice `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(images), kms.n_clusters), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche par similarité\n",
    "\n",
    "**À faire -** Ecrivez le code pour calculer la distance Euclidienne entre les images requetes et toutes les images, stockez les resultats dans la matrice `dist`.\n",
    "\n",
    "**Aide -** Regardez l'aide de la fonction : [`sklearn.metrics.pairwise.euclidean_distances`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "dist = ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À faire -** Ecrivez le code pour afficher la matrice des distance `dist`.\n",
    "\n",
    "**Aide -** Regardez l'aide de la fonction : [`matplotlib.pyplot.matshow`](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.matshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À faire -** Choisissez une requete et ecrivez le code pour afficher les 15 images les plus similaire a la requete.\n",
    "\n",
    "**Aide -** Regardez l'aide des fonctions : [`numpy.argsort`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html), [`matplotlib.pyplot.imshow`](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.imshow) et [`matplotlib.pyplot.subplot`](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.subplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour evaluer la performance de notre representation et de la metrique que nous utilisons pour calculer la distance entre les images, nous utilisons la mesure de performence officiler de la base Holidays le mAP ([mean Average Precision](https://en.wikipedia.org/wiki/Information_retrieval#Mean_average_precision)).\n",
    "\n",
    "La fonction `def score_map(dist, y, queries)` retourne le mAP pour la matrice de distance `dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_ap_from_ranks_1 (ranks, nres):\n",
    "    ap=0.0\n",
    "    recall_step=1.0/nres\n",
    "    for ntp,rank in enumerate(ranks):\n",
    "        if rank==0: \n",
    "            precision_0=1.0\n",
    "        else:\n",
    "            precision_0=ntp/float(rank)\n",
    "        precision_1=(ntp+1)/float(rank+1)\n",
    "        ap+=(precision_1+precision_0)*recall_step/2.0\n",
    "    return ap\n",
    "\n",
    "def score_map(dist, y, queries):\n",
    "    queries_label = -1*np.ones(queries.shape)\n",
    "    queries_label[queries] = y[queries]\n",
    "    \n",
    "    idxsortdist = np.argsort(dist, axis=1)\n",
    "    \n",
    "    mAP = 0.0;\n",
    "\n",
    "    for r in y[queries]:\n",
    "        y_r = y[idxsortdist[r,:]]\n",
    "        queries_label_r = queries_label[idxsortdist[r,:]]\n",
    "        \n",
    "        nres = np.sum(np.logical_and(y == r, queries_label != r))\n",
    "        \n",
    "        tp_ranks = np.sort(np.where(y_r[queries_label_r != r] == r)[0])\n",
    "        \n",
    "        ap = score_ap_from_ranks_1 (tp_ranks, nres)\n",
    "\n",
    "        mAP += ap\n",
    "    return mAP/ np.sum(queries) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À faire -** Ecrivez le code pour calculer la performence de notre representation avec la distance euclidienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons nous comparer aux performances de l'état de l'art sur le [site de la base Holidays](http://lear.inrialpes.fr/~jegou/holidays_state_of_art.html) (section : Global descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentisage de métrique et Validation croisée\n",
    "\n",
    "Nous voyons que la performance de notre représentation avec la métrique Euclidienne n'est pas très bonne en comparaisons aux méthodes de l'états de l'art. Mais elle est tout de même bien meilleure que le hasard qui donne en moyenne un mAP de 0.337%.\n",
    "\n",
    "Nous pouvons améliorer la performance de notre représentation par l'histogramme couleur des images en apprenant une métrique adaptée à notre problème de recherche par similarité.\n",
    "\n",
    "### Distance de Mahalanobis\n",
    "\n",
    "Pour ce TD, nous utiliserons la [distance de Mahalanobis](https://en.wikipedia.org/wiki/Mahalanobis_distance) qui a pour équation :\n",
    "\\begin{equation}\n",
    "d_\\mathbf{W}(\\mathbf{x}, \\mathbf{y})^2 = (\\mathbf{x} - \\mathbf{y})\\mathbf{W}(\\mathbf{x} - \\mathbf{y})^\\top\n",
    "\\end{equation} \n",
    "avec $\\mathbf{x} \\in \\mathbb{R}^P$, $\\mathbf{x} \\in \\mathbb{R}^P$ et $\\mathbf{W} \\in \\mathcal{M}_{P \\times P}$.\n",
    "\n",
    "La distance de Mahalanobis est donc un métrique paramétrable par la matrice $\\mathbf{W}$, nous allons donc chercher le meilleur $\\mathbf{W}$ pour obtenir les meilleurs performances en recherche par similarité avec notre représentation par histogramme couleur.\n",
    "\n",
    "Nous voyons que la distance de Mahalanobis est une extention de la [distance Euclidienne](https://en.wikipedia.org/wiki/Euclidean_distance), en effet si nous posons $\\mathbf{W}$ égale à la matrice identité, nous obtenons :\n",
    "\n",
    "\\begin{equation}\n",
    "d_\\mathbf{I}(\\mathbf{x}, \\mathbf{y})^2 = (\\mathbf{x} - \\mathbf{y})\\mathbf{I}(\\mathbf{x} - \\mathbf{y})^\\top = (\\mathbf{x} - \\mathbf{y})(\\mathbf{x} - \\mathbf{y})^\\top = \\|\\mathbf{x} - \\mathbf{y}\\|_2^2\n",
    "\\end{equation}\n",
    "\n",
    "Une contrainte difficile à prendre en compte quand on veut apprendre une métrique avec la distance de Mahalanobis est la contrainte de semi-positivité de la matrice $\\mathbf{W} \\succcurlyeq 0$. Cette contrainte permet de garantir que la distance de Mahalanobis est toujours supérieur ou égale à zéro : $d_\\mathbf{W}(\\mathbf{x}, \\mathbf{y})^2 \\geqslant 0$. Pour éviter ce probleme nous faisons le changement de variable suivant : $\\mathbf{W} = \\mathbf{U}^\\top\\mathbf{U}$ avec $\\mathbf{U} \\in \\mathcal{M}_{p \\times P}$ une matrice et $0 < p \\leqslant P$. Nous obtenons alors la distance suivante :\n",
    "\n",
    "\\begin{equation}\n",
    "d_{\\mathbf{U}^\\top\\mathbf{U}}(\\mathbf{x}, \\mathbf{y})^2 = (\\mathbf{x} - \\mathbf{y})\\mathbf{U}^\\top\\mathbf{U}(\\mathbf{x} - \\mathbf{y})^\\top\n",
    "\\end{equation}\n",
    "\n",
    "De plus, il est possible de réécrire cette distance pour utiliser directement le distance Euclidienne :\n",
    "\\begin{eqnarray}\n",
    "d_{\\mathbf{U}^\\top\\mathbf{U}}(\\mathbf{x}, \\mathbf{y})^2 & = &(\\mathbf{x} - \\mathbf{y})\\mathbf{U}^\\top\\mathbf{U}(\\mathbf{x} - \\mathbf{y})^\\top\\\\\n",
    "& = & (\\mathbf{x}\\mathbf{U}^\\top - \\mathbf{y}\\mathbf{U}^\\top)(\\mathbf{x}\\mathbf{U}^\\top - \\mathbf{y}\\mathbf{U}^\\top)^\\top\\\\\n",
    "& = & d(\\mathbf{x}\\mathbf{U}^\\top, \\mathbf{y}\\mathbf{U}^\\top)^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "### Apprentisage de métrique\n",
    "\n",
    "Pour apprendre la métrique la plus adaptée à notre problème de recherche par similarité nous allons chercher à apprendre une métrique qui respecte l'ensemble des contraintes suivant :\n",
    "\\begin{equation}\n",
    "\\left\\{ d_{\\mathbf{U}^\\top\\mathbf{U}}(\\mathbf{x}_{i1}, \\mathbf{x}_{i2})^2 < d_{\\mathbf{U}^\\top\\mathbf{U}}(\\mathbf{x}_{j1}, \\mathbf{x}_{j2})^2 \\right\\}_{(\\mathbf{x}_{i1}, \\mathbf{x}_{i2})\\in \\mathcal{S}, (\\mathbf{x}_{j1}, \\mathbf{x}_{j2})\\in \\mathcal{D}}\n",
    "\\end{equation}\n",
    "avec $\\mathcal{S}$ l'ensemble des couples d'images similaires  et $\\mathcal{D}$ l'ensemble des couples d'images dissimilaires.\n",
    "\n",
    "En clair nous voulons que la distance entre deux images similaire soit toujours plus petite que la distance entre deux images dissimilaire.\n",
    "\n",
    "Pour apprendre notre métrique, nous allons utiliser l'ensemble des images qui ne sont pas des requêtes, le code suivant permet de créer l'ensemble d'entrainement  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rs: indice des images chaque groupe, et counts = le nombre de photos dans chaque groupe (sans la requete)\n",
    "rs, counts = np.unique(y[~queries], return_counts=True)\n",
    "# on elimine les indices des groupes ne contenant qu'une seule image\n",
    "mask = np.any(np.equal(y[:,np.newaxis], rs[counts > 1][np.newaxis,:]),axis=1)\n",
    "\n",
    "y_train = y[mask] # indice\n",
    "X_train = X[mask, :] # nombre de couleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons maintenant crée l'ensemble des couples d'images similaire $\\mathcal{S}$ et l'ensemble des couples d'images dissimilaire $\\mathcal{D}$ que nous utiliserons pour apprendre notre métrique.\n",
    "\n",
    "Le code suivant permet de créer les ensembles $\\mathcal{S}$ et $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = np.equal(y_train[:, np.newaxis], y_train[np.newaxis, :])\n",
    "S = np.vstack(np.where(np.logical_and(G, np.tri(y_train.shape[0], k=-1, dtype=bool))))\n",
    "D = np.vstack(np.where(np.logical_and(np.logical_not(G), np.tri(y_train.shape[0], k=-1, dtype=bool))))\n",
    "\n",
    "print(\"Nombre de couple d'images similaire :\", S.shape[1])\n",
    "print(\"Nombre de couple d'images dissimilaire :\",D.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que le nombre de couple d'image dissimilaire est beaucoup plus grand que le nombre de couple d'image similaire, cela est normal mais pour des raisons de temps de calcul nous allons réduire le nombre de couple d'image dissimilaire.\n",
    "\n",
    "Le code suivant échantillons aléatoirement 8000 couple d'images dissimilaire parmi les 455641 d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = D[:, np.random.choice(D.shape[1], 8000, replace=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour apprendre notre métrique nous voulons trouver le parametre $\\mathbf{U}$ qui minimise la fonction objective suivante :\n",
    "\\begin{equation}\n",
    "f(\\mathbf{U}) = \\sum_{(\\mathbf{x}_{i1}, \\mathbf{x}_{i2})\\in \\mathcal{S}}\\sum_{(\\mathbf{x}_{j1}, \\mathbf{x}_{j2})\\in \\mathcal{D}} \\max(0, d_{\\mathbf{U}^\\top\\mathbf{U}}(\\mathbf{x}_{i1}, \\mathbf{x}_{i2}) - d_{\\mathbf{U}^\\top\\mathbf{U}}(\\mathbf{x}_{j1}, \\mathbf{x}_{j2}) + 1) + \\lambda \\|\\mathbf{U}\\|_F^2\n",
    "\\end{equation} \n",
    "avec $\\mathbf{U} \\in \\mathcal{M}_{p \\times P}$ le parametre à apprendre, $\\|\\cdot\\|_F^2$ la [norme de Frobenius](https://fr.wikipedia.org/wiki/Norme_matricielle#Norme_de_Frobenius), $\\mathcal{S}$ l'ensemble des couples d'images similaires, $\\mathcal{D}$ l'ensemble des couples d'images dissimilaires et $\\lambda$ un hyperparamètre.\n",
    "\n",
    "La partie $+ \\lambda \\|\\mathbf{U}\\|_F^2$ de la fonction objective est une partie de régularisation qui permet d'éviter les problèmes de surapprentissage.\n",
    "\n",
    "Notre fonction objetctive a donc deux hyperparamètres :\n",
    "- $\\lambda$ : pour la régularisation\n",
    "- $p$, le nombre de ligne de la matrice $\\mathbf{U}$\n",
    "\n",
    "La classe suivante permet de calculer la fonction objective et son gradient. A la construction de la classe, nous lui donnons l'ensemble des représentations d'entrainements `X_train`, les couples d'image similaires `S`, les couples d'images dissimilaire `D` et la dimensions de la matrice `U`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class metric_learning:\n",
    "    def __init__(self, X, S, D, U_shape):\n",
    "        self.X = X\n",
    "        self.S = S\n",
    "        self.D = D\n",
    "        self.U_shape = U_shape\n",
    "        \n",
    "        self.dXs = self.X[self.S[0,:],:] - self.X[self.S[1,:],:]\n",
    "        self.dXd = self.X[self.D[0,:],:] - self.X[self.D[1,:],:]\n",
    "\n",
    "    def compute_objective_func(self, U, lambda_coef = 1000):\n",
    "        U = np.reshape(U,self.U_shape)\n",
    "        dYs = np.dot(self.dXs, U.T)\n",
    "        dYd = np.dot(self.dXd, U.T)\n",
    "\n",
    "        dp = np.sum(np.power(dYs,2),axis=1)\n",
    "        dn = np.sum(np.power(dYd,2),axis=1)\n",
    "        \n",
    "        dp_max = np.max(dp)\n",
    "        dn_min = np.min(dn)\n",
    "        \n",
    "        mask_dp = dp - dn_min + 1 > 0\n",
    "        mask_dn = dp_max - dn + 1 > 0\n",
    "        \n",
    "        f = np.sum(np.maximum(0, dp[mask_dp, np.newaxis] - dn[np.newaxis, mask_dn] + 1))\n",
    "        f = f + lambda_coef * np.linalg.norm(U,'fro')**2\n",
    "        return f\n",
    "    \n",
    "    def compute_gradient_func(self, U, lambda_coef = 1000):\n",
    "        \n",
    "        U = np.reshape(U,self.U_shape)\n",
    "        \n",
    "        dYs = np.dot(self.dXs, U.T)\n",
    "        dYd = np.dot(self.dXd, U.T)\n",
    "\n",
    "        dp = np.sum(np.power(dYs,2),axis=1)\n",
    "        dn = np.sum(np.power(dYd,2),axis=1)\n",
    "        \n",
    "        dp_max = np.max(dp)\n",
    "        dn_min = np.min(dn)\n",
    "        \n",
    "        mask_dp = dp - dn_min + 1 > 0\n",
    "        mask_dn = dp_max - dn + 1 > 0\n",
    "        \n",
    "        \n",
    "        h = dp[mask_dp, np.newaxis] - dn[np.newaxis, mask_dn] >= -1\n",
    "         \n",
    "        Gp = np.dot(np.multiply(dYs[mask_dp,:].T, np.sum(h,axis=1)),self.dXs[mask_dp,:])\n",
    "        Gn = np.dot(np.multiply(dYd[mask_dn,:].T, np.sum(h,axis=0)),self.dXd[mask_dn,:])\n",
    "        G = (Gp - Gn)\n",
    "        G = G + lambda_coef * U\n",
    "        G = 2*G.flatten()\n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À faire -** Utilisez la fonction d'optimisation [`scipy.optimize.fmin_cg`](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.optimize.fmin_cg.html) pour trouvé la valeur optimale de $\\mathbf{U}$. Nous fixons dans un premier temps les  hyperparamètres à $p=8$ et $\\lambda = 100$\n",
    "\n",
    "**Aide -** Regardez l'aide des fonctions : [`scipy.optimize.fmin_cg`](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.optimize.fmin_cg.html) (lire attentivement la description du paramètre args) et [`sklearn.decomposition.PCA`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html).\n",
    "\n",
    "\n",
    "**Conseil -** Utilisez les vecteurs de la PCA `PCA.components_` sur les données `X_train` comme point de départ `U0` et ajoutez le paramètre : `gtol=10` pour la fonction `fmin_cg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "p = 8\n",
    "lambda_coef = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À faire -** Ecrivez le code pour calculer la performance (mAP) en recherche pas similarité avec la metrique de Mahalanobis obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation croisée\n",
    "\n",
    "Nous avons appris une métrique adaptée à notre problème de recherche par similarité mais nous avons choisi arbitrairement les valeurs des hyperparamètres. Nous voyons que la performance obtenue est moins bonne que celle obtenu avec la distance Euclidienne. Il nous faut donc chercher les meilleures valeurs pour les hyperparamètres.\n",
    "\n",
    "Pour cela, nous allons tester plusieurs valeurs pour $p$ et $\\lambda$ et choisir les valeurs qui donne la meilleure performance sur notre ensemble de validation (Pour TD, nous considérerons l'ensemble des requêtes de test comme notre ensemble de validation, ce qui n'est pas correcte dans la pratique).\n",
    "\n",
    "**À faire -** Ecrivez un code pour tester toute les combinaisons possibles pour les hyperparamètres avec $p \\in \\{8, 16, 32\\}$ et $\\lambda \\in \\{10,10^{1.25},10^{1.5},10^{1.75},10^{2},10^{2.25},10^{2.5},10^{2.75},10^{3},10^{3.25},10^{3.5}\\}$ et qui choisit la meilleur.\n",
    "\n",
    "**Conseil -** Ajoutez le paramètre : `disp=0` pour la fonction `fmin_cg`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = (8, 16, 32)\n",
    "lambda_coefs = (10**1, 10**1.25, 10**1.5, 10**1.75, 10**2, 10**2.25, 10**2.5, 10**2.75, 10**3, 10**3.25, 10**3.5)\n",
    "\n",
    "best_mAP = 0.0"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
